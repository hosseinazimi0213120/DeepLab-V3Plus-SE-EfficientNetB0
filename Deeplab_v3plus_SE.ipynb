{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZbe2Da1BRPp"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwahvp9jsh5e"
      },
      "outputs": [],
      "source": [
        "#%tensorflow_version 2.x\n",
        "import cv2, numpy as np, matplotlib, matplotlib.pyplot as plt, numba, random, glob, os, tensorflow as tf, keras\n",
        "from numba import cuda\n",
        "\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread, imshow, imsave\n",
        "from contextlib import redirect_stdout\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Add, Lambda, UpSampling2D\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, GlobalAveragePooling2D, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, ZeroPadding2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16, VGG19, InceptionResNetV2\n",
        "\n",
        "import keras.backend as k\n",
        "from keras.layers import *\n",
        "from keras.layers import SpatialDropout2D, Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate,AveragePooling2D, UpSampling2D, BatchNormalization, Activation, add,Dropout,Permute,ZeroPadding2D,Add, Reshape\n",
        "from keras.layers import ELU, PReLU, LeakyReLU\n",
        "\n",
        "from keras.models import *\n",
        "from keras.models import Model, model_from_json\n",
        "\n",
        "from keras.optimizers import *\n",
        "from keras import applications, optimizers, callbacks\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras import initializers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJsnxJ5l6ww_"
      },
      "source": [
        "Model 1: DeepLabv3Plus-Resnet50 and 101\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq8fpRPE6z-H"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50, ResNet101\n",
        "\n",
        "\"\"\" Atrous Spatial Pyramid Pooling \"\"\"\n",
        "def ASPP(inputs):\n",
        "    shape = inputs.shape\n",
        "\n",
        "    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]), name='average_pooling')(inputs)\n",
        "    y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
        "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
        "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
        "    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
        "\n",
        "    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(inputs)\n",
        "    y_1 = BatchNormalization()(y_1)\n",
        "    y_1 = Activation('relu')(y_1)\n",
        "\n",
        "    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same', use_bias=False)(inputs)\n",
        "    y_6 = BatchNormalization()(y_6)\n",
        "    y_6 = Activation('relu')(y_6)\n",
        "\n",
        "    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same', use_bias=False)(inputs)\n",
        "    y_12 = BatchNormalization()(y_12)\n",
        "    y_12 = Activation('relu')(y_12)\n",
        "\n",
        "    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same', use_bias=False)(inputs)\n",
        "    y_18 = BatchNormalization()(y_18)\n",
        "    y_18 = Activation('relu')(y_18)\n",
        "\n",
        "    y = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
        "\n",
        "    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    return y\n",
        "\n",
        "def DeepLabV3Plus_resnet50(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 \"\"\"\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 Output \"\"\"\n",
        "    image_features = base_model.get_layer('conv4_block6_out').output\n",
        "    x_a = ASPP(image_features)\n",
        "    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n",
        "\n",
        "    \"\"\" Get low-level features \"\"\"\n",
        "    x_b = base_model.get_layer('conv2_block2_out').output\n",
        "    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
        "    x_b = BatchNormalization()(x_b)\n",
        "    x_b = Activation('relu')(x_b)\n",
        "\n",
        "    x = Concatenate()([x_a, x_b])\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    x = Conv2D(n_classes, (1, 1), name='output_layer')(x)\n",
        "    x = Activation('softmax')(x)\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=metrics)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def DeepLabV3Plus_resnet101(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet1-1 \"\"\"\n",
        "    base_model = ResNet101(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet101 Output \"\"\"\n",
        "    image_features = base_model.get_layer('conv4_block6_out').output\n",
        "    x_a = ASPP(image_features)\n",
        "    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n",
        "\n",
        "    \"\"\" Get low-level features \"\"\"\n",
        "    x_b = base_model.get_layer('conv2_block2_out').output\n",
        "    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
        "    x_b = BatchNormalization()(x_b)\n",
        "    x_b = Activation('relu')(x_b)\n",
        "\n",
        "    x = Concatenate()([x_a, x_b])\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    x = Conv2D(n_classes, (1, 1), name='output_layer')(x)\n",
        "    x = Activation('softmax')(x)\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=[dice_acc])\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki0uW6STVsi4"
      },
      "source": [
        "Model 2: DeepLabV3plusSE_EfficientNetB0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzlTPTjMVwG7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "def SqueezeAndExcitation(inputs, ratio=8):\n",
        "\n",
        "    b, h, w, c = inputs.shape\n",
        "    x = GlobalAveragePooling2D()(inputs)\n",
        "    x = Dense(c//ratio, activation='relu', use_bias=False)(x)\n",
        "    x = Dense(c, activation='sigmoid', use_bias=False)(x)\n",
        "    x = Multiply()([inputs, x])\n",
        "    return x\n",
        "\n",
        "\n",
        "def ASPP(image_features):\n",
        "    shape = image_features.shape\n",
        "    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]))(image_features)\n",
        "    y_pool = Conv2D(filters=128, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
        "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
        "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
        "    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
        "\n",
        "    y_1 = Conv2D(filters=128, kernel_size=1, padding='same', use_bias=False)(image_features)\n",
        "    y_1 = BatchNormalization(name=f'bn_2')(y_1)\n",
        "    y_1 = Activation('relu', name=f'relu_2')(y_1)\n",
        "\n",
        "    y_6 = Conv2D(filters=128, kernel_size=3, padding='same', dilation_rate = 6,use_bias=False)(image_features)\n",
        "    y_6 = BatchNormalization(name=f'bn_3')(y_6)\n",
        "    y_6 = Activation('relu', name=f'relu_3')(y_6)\n",
        "\n",
        "    y_12 = Conv2D(filters=128, kernel_size=1, padding='same', dilation_rate = 12,use_bias=False)(image_features)\n",
        "    y_12 = BatchNormalization(name=f'bn_4')(y_12)\n",
        "    y_12 = Activation('relu', name=f'relu_4')(y_12)\n",
        "\n",
        "    y_18 = Conv2D(filters=128, kernel_size=3, padding='same', dilation_rate = 6,use_bias=False)(image_features)\n",
        "    y_18 = BatchNormalization(name=f'bn_5')(y_18)\n",
        "    y_18 = Activation('relu', name=f'relu_5')(y_18)\n",
        "\n",
        "    y_c = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
        "\n",
        "    y = Conv2D(filters=128, kernel_size=1, padding='same', use_bias=False)(y_c)\n",
        "    y = BatchNormalization(name=f'bn_6')(y)\n",
        "    y = Activation('relu', name=f'relu_6')(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "def DeepLabV3plusSE_EfficientNetB0(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=inputs, drop_connect_rate=0.25)\n",
        "    high_level_image_features = base_model.get_layer('block6a_expand_bn').output\n",
        "    high_level_image_features = SqueezeAndExcitation(high_level_image_features, ratio=16)\n",
        "\n",
        "    x_a = ASPP(high_level_image_features)\n",
        "    x_a = SqueezeAndExcitation(x_a, ratio=16)\n",
        "    x_a = UpSampling2D(size=4, interpolation='bilinear')(x_a)\n",
        "\n",
        "    low_level_image_features = base_model.get_layer('block3a_expand_bn').output\n",
        "    low_level_image_features = SqueezeAndExcitation(low_level_image_features, ratio=16)\n",
        "\n",
        "    x_b = Conv2D(filters=128, kernel_size=1, padding='same', use_bias=False)(low_level_image_features)\n",
        "    x_b = BatchNormalization(name=f'bn_7')(x_b)\n",
        "    x_b = Activation('relu', name=f'relu_7')(x_b)\n",
        "\n",
        "    x = Concatenate()([x_a, x_b])\n",
        "    x  = SqueezeAndExcitation(x, ratio=16)\n",
        "\n",
        "    x = Conv2D(filters=128, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_8')(x)\n",
        "    x = Activation('relu', name=f'relu_8')(x)\n",
        "\n",
        "    x = Conv2D(filters=128, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_9')(x)\n",
        "    x = Activation('relu', name=f'relu_9')(x)\n",
        "\n",
        "    x = UpSampling2D(size=4, interpolation='bilinear')(x)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    x = Conv2D(n_classes, kernel_size=1, name='output_layer')(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=metrics)\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTbmkXaOYhcV"
      },
      "source": [
        "Model 3: DeepLabV3plus_DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qojoyGs1Yh6-"
      },
      "outputs": [],
      "source": [
        "from keras.applications.densenet import DenseNet121\n",
        "\n",
        "\n",
        "def ASPP(image_features):\n",
        "\n",
        "  shape = image_features.shape\n",
        "\n",
        "  y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]))(image_features)\n",
        "  y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
        "  y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
        "  y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
        "  y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
        "\n",
        "  y_1 = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(image_features)\n",
        "  y_1 = BatchNormalization(name=f'bn_2')(y_1)\n",
        "  y_1 = Activation('relu', name=f'relu_2')(y_1)\n",
        "\n",
        "  y_6 = Conv2D(filters=256, kernel_size=3, padding='same', dilation_rate = 6,use_bias=False)(image_features)\n",
        "  y_6 = BatchNormalization(name=f'bn_3')(y_6)\n",
        "  y_6 = Activation('relu', name=f'relu_3')(y_6)\n",
        "\n",
        "  y_12 = Conv2D(filters=256, kernel_size=1, padding='same', dilation_rate = 12,use_bias=False)(image_features)\n",
        "  y_12 = BatchNormalization(name=f'bn_4')(y_12)\n",
        "  y_12 = Activation('relu', name=f'relu_4')(y_12)\n",
        "\n",
        "  y_18 = Conv2D(filters=256, kernel_size=3, padding='same', dilation_rate = 6,use_bias=False)(image_features)\n",
        "  y_18 = BatchNormalization(name=f'bn_5')(y_18)\n",
        "  y_18 = Activation('relu', name=f'relu_5')(y_18)\n",
        "\n",
        "  y_c = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
        "\n",
        "  y = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_c)\n",
        "  y = BatchNormalization(name=f'bn_6')(y)\n",
        "  y = Activation('relu', name=f'relu_6')(y)\n",
        "\n",
        "  return y\n",
        "\n",
        "\n",
        "def DeepLabV3plus_DenseNet121(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    high_level_image_features = base_model.get_layer('pool4_relu').output\n",
        "\n",
        "    x_a = ASPP(high_level_image_features)\n",
        "    x_a = UpSampling2D(size=4, interpolation='bilinear')(x_a)\n",
        "\n",
        "    low_level_image_features = base_model.get_layer('pool2_relu').output\n",
        "\n",
        "    x_b = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(low_level_image_features)\n",
        "    x_b = BatchNormalization(name=f'bn_7')(x_b)\n",
        "    x_b = Activation('relu', name=f'relu_7')(x_b)\n",
        "\n",
        "    x = Concatenate()([x_a, x_b])\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_8')(x)\n",
        "    x = Activation('relu', name=f'relu_8')(x)\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_9')(x)\n",
        "    x = Activation('relu', name=f'relu_9')(x)\n",
        "\n",
        "    x = UpSampling2D(size=4, interpolation='bilinear')(x)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    x = Conv2D(n_classes, 1, name='output_layer')(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=metrics)\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtVk80lxa_3t"
      },
      "source": [
        "Model: DeepLabV3plus_VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geImorOzbBp8"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "\n",
        "def ASPP(image_features):\n",
        "\n",
        "    shape = image_features.shape\n",
        "\n",
        "    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]))(image_features)\n",
        "    y_pool = Conv2D(filters=128, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
        "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
        "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
        "    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
        "\n",
        "    y_1 = Conv2D(filters=128, kernel_size=1, padding='same', use_bias=False)(image_features)\n",
        "    y_1 = BatchNormalization(name=f'bn_2')(y_1)\n",
        "    y_1 = Activation('relu', name=f'relu_2')(y_1)\n",
        "\n",
        "    y_6 = Conv2D(filters=128, kernel_size=3, padding='same', dilation_rate = 6,use_bias=False)(image_features)\n",
        "    y_6 = BatchNormalization(name=f'bn_3')(y_6)\n",
        "    y_6 = Activation('relu', name=f'relu_3')(y_6)\n",
        "\n",
        "    y_12 = Conv2D(filters=128, kernel_size=1, padding='same', dilation_rate = 12,use_bias=False)(image_features)\n",
        "    y_12 = BatchNormalization(name=f'bn_4')(y_12)\n",
        "    y_12 = Activation('relu', name=f'relu_4')(y_12)\n",
        "\n",
        "    y_18 = Conv2D(filters=128, kernel_size=3, padding='same', dilation_rate = 6,use_bias=False)(image_features)\n",
        "    y_18 = BatchNormalization(name=f'bn_5')(y_18)\n",
        "    y_18 = Activation('relu', name=f'relu_5')(y_18)\n",
        "\n",
        "    y_c = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
        "\n",
        "    y = Conv2D(filters=128, kernel_size=1, padding='same', use_bias=False)(y_c)\n",
        "    y = BatchNormalization(name=f'bn_6')(y)\n",
        "    y = Activation('relu', name=f'relu_6')(y)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def DeepLabV3plus_VGG16(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    high_level_image_features = base_model.get_layer('block5_conv3').output\n",
        "\n",
        "    x_a = ASPP(high_level_image_features)\n",
        "    x_a = UpSampling2D(size=4, interpolation='bilinear')(x_a)\n",
        "\n",
        "    low_level_image_features = base_model.get_layer('block3_conv3').output\n",
        "\n",
        "    x_b = Conv2D(filters=128, kernel_size=1, padding='same', use_bias=False)(low_level_image_features)\n",
        "    x_b = BatchNormalization(name=f'bn_7')(x_b)\n",
        "    x_b = Activation('relu', name=f'relu_7')(x_b)\n",
        "\n",
        "    x = Concatenate()([x_a, x_b])\n",
        "\n",
        "    x = Conv2D(filters=128, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_8')(x)\n",
        "    x = Activation('relu', name=f'relu_8')(x)\n",
        "\n",
        "    x = Conv2D(filters=128, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_9')(x)\n",
        "    x = Activation('relu', name=f'relu_9')(x)\n",
        "\n",
        "    x = UpSampling2D(size=4, interpolation='bilinear')(x)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    x = Conv2D(n_classes, 1, name='output_layer')(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=metrics)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyhGA09fc0JU"
      },
      "source": [
        "Model 7: Deeplabv3p_PSPNet_SqEx_SegModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrKOwpnDc2d_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, Multiply\n",
        "from tensorflow.keras.applications import EfficientNetB2\n",
        "\n",
        "\n",
        "def SqueezeAndExcitation(inputs, ratio=8):\n",
        "\n",
        "    b, h, w, c = inputs.shape\n",
        "\n",
        "    x = GlobalAveragePooling2D()(inputs)\n",
        "    x = Dense(c//ratio, activation='relu', use_bias=False)(x)\n",
        "    x = Dense(c, activation='sigmoid', use_bias=False)(x)\n",
        "\n",
        "    x = Multiply()([inputs, x])\n",
        "\n",
        "    return x\n",
        "\n",
        "def Pyramid_Pooling_Module(features, f=32, p1=2, p2=3, p3=8):\n",
        "\n",
        "    shape = features.shape\n",
        "    red = GlobalAveragePooling2D()(features)\n",
        "    red = Reshape((1,1,shape[-1]))(red)\n",
        "    red = Conv2D(filters=f, kernel_size=(1,1), padding='same', use_bias=False)(red)\n",
        "    red = BatchNormalization()(red)\n",
        "    red = Activation('relu')(red)\n",
        "    red = UpSampling2D(size=shape[1],interpolation='bilinear')(red)\n",
        "\n",
        "    orange = AveragePooling2D(pool_size=(p1))(features)\n",
        "    orange = Conv2D(filters=f, kernel_size=(1,1), padding='same', use_bias=False)(orange)\n",
        "    orange = BatchNormalization()(orange)\n",
        "    orange = Activation('relu')(orange)\n",
        "    orange = UpSampling2D(size=p1,interpolation='bilinear')(orange)\n",
        "\n",
        "    blue = AveragePooling2D(pool_size=(p2))(features)\n",
        "    blue = Conv2D(filters=f, kernel_size=(1,1), padding='same', use_bias=False)(blue)\n",
        "    blue = BatchNormalization()(blue)\n",
        "    blue = Activation('relu')(blue)\n",
        "    blue = UpSampling2D(size=p2,interpolation='bilinear')(blue)\n",
        "\n",
        "    green = AveragePooling2D(pool_size=(p3))(features)\n",
        "    green = Conv2D(filters=f, kernel_size=(1,1), padding='same', use_bias=False)(green)\n",
        "    green = BatchNormalization()(green)\n",
        "    green = Activation('relu')(green)\n",
        "    green = UpSampling2D(size=p3,interpolation='bilinear')(green)\n",
        "\n",
        "    return Concatenate()([features, red, orange, blue, green])\n",
        "\n",
        "def ASPP(image_features):\n",
        "\n",
        "    shape = image_features.shape\n",
        "\n",
        "    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]))(image_features)\n",
        "    y_pool = Conv2D(filters=32, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
        "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
        "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
        "    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
        "\n",
        "    y_1 = Conv2D(filters=32, kernel_size=1, padding='same', use_bias=False)(image_features)\n",
        "    y_1 = BatchNormalization(name=f'bn_2')(y_1)\n",
        "    y_1 = Activation('relu', name=f'relu_2')(y_1)\n",
        "\n",
        "    y_6 = Conv2D(filters=32, kernel_size=3, padding='same', dilation_rate = 6,use_bias=False)(image_features)\n",
        "    y_6 = BatchNormalization(name=f'bn_3')(y_6)\n",
        "    y_6 = Activation('relu', name=f'relu_3')(y_6)\n",
        "\n",
        "    y_12 = Conv2D(filters=32, kernel_size=1, padding='same', dilation_rate = 12,use_bias=False)(image_features)\n",
        "    y_12 = BatchNormalization(name=f'bn_4')(y_12)\n",
        "    y_12 = Activation('relu', name=f'relu_4')(y_12)\n",
        "\n",
        "    y_18 = Conv2D(filters=32, kernel_size=3, padding='same', dilation_rate = 6,use_bias=False)(image_features)\n",
        "    y_18 = BatchNormalization(name=f'bn_5')(y_18)\n",
        "    y_18 = Activation('relu', name=f'relu_5')(y_18)\n",
        "\n",
        "    y_c = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
        "\n",
        "    y = Conv2D(filters=32, kernel_size=1, padding='same', use_bias=False)(y_c)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def Deeplabv3p_PSPNet_SqEx_SegModel(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    base_model = EfficientNetB2(weights='imagenet', include_top=False, input_tensor=inputs, drop_connect_rate=0.25)\n",
        "    high_level_image_features = base_model.get_layer('block6a_expand_bn').output\n",
        "    # high_level_image_features = SqueezeAndExcitation(high_level_image_features, ratio=16)\n",
        "\n",
        "    x_a = ASPP(high_level_image_features)\n",
        "    x_a = SqueezeAndExcitation(x_a, ratio=16)\n",
        "\n",
        "    x_b = Pyramid_Pooling_Module(high_level_image_features, f=32, p1=2, p2=4, p3=8)\n",
        "    x_b = Conv2D(filters=32, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
        "    x_b = BatchNormalization()(x_b)\n",
        "    x_b = Activation('relu')(x_b)\n",
        "    x_b = SqueezeAndExcitation(x_b, ratio=16)\n",
        "\n",
        "    x_c = Concatenate()([x_a, x_b])\n",
        "    x_c = Conv2D(filters=32, kernel_size=1, padding='same', use_bias=False)(x_c)\n",
        "    x_c = BatchNormalization()(x_c)\n",
        "    x_c = Activation('relu')(x_c)\n",
        "    x_c = SqueezeAndExcitation(x_c, ratio=16)\n",
        "    x_c = UpSampling2D(size=4, interpolation='bilinear')(x_c)\n",
        "\n",
        "    low_level_image_features = base_model.get_layer('block3a_expand_bn').output\n",
        "    x_d = Conv2D(filters=32, kernel_size=1, padding='same', use_bias=False)(low_level_image_features)\n",
        "    x_d = BatchNormalization()(x_d)\n",
        "    x_d = Activation('relu')(x_d)\n",
        "\n",
        "    x_e = Concatenate()([x_c, x_d])\n",
        "    x_e = Conv2D(filters=32, kernel_size=1, padding='same', use_bias=False)(x_e)\n",
        "    x_e = BatchNormalization()(x_e)\n",
        "    x_e = Activation('relu')(x_e)\n",
        "    x_e = SqueezeAndExcitation(x_e, ratio=16)\n",
        "\n",
        "    x = Conv2D(filters=32, kernel_size=3, padding='same', use_bias=False)(x_e)\n",
        "    x = BatchNormalization(name=f'bn_8')(x)\n",
        "    x = Activation('relu', name=f'relu_8')(x)\n",
        "\n",
        "    x = Conv2D(filters=32, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name=f'bn_9')(x)\n",
        "    x = Activation('relu', name=f'relu_9')(x)\n",
        "\n",
        "    x = UpSampling2D(size=4, interpolation='bilinear')(x)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    x = Conv2D(n_classes, 1, name='output_layer')(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=metrics)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE_X = 256\n",
        "SIZE_Y = 256\n",
        "n_classes= 3\n",
        "def get_model():\n",
        "    return DeepLabV3plusSE_EfficientNetB0(n_classes=n_classes, IMG_HEIGHT=SIZE_Y, IMG_WIDTH=SIZE_X, IMG_CHANNELS=1)\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2k0GDh1o3_3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDFA_vfLAawI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "with strategy.scope():\n",
        "    model = DeepLabV3plusSE_EfficientNetB0()\n",
        "#DeepLabV3Plus_resnet50\n",
        "#DeepLabV3Plus_resnet101\n",
        "#DeepLabV3plusSE_EfficientNetB0\n",
        "#DeepLabV3plus_DenseNet121\n",
        "#DeepLabV3plus_VGG16\n",
        "#Deeplabv3p_PSPNet_SqEx_SegModel"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3.7.5 (TF_GPU)",
      "language": "python",
      "name": "tf_gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}